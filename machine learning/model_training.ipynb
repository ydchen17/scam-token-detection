{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def objective(trial, df, y):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-8, 1e5),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 1e-5, 1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1e2),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1e2),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1e2)\n",
    "    }\n",
    "    kf = StratifiedKFold(n_splits=3, random_state=15, shuffle=True)\n",
    "\n",
    "    y_hats = []\n",
    "    y_tests = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df, y):\n",
    "        X_train, X_test = df.iloc[train_index], df.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_hats += model.predict(X_test).tolist()\n",
    "        y_tests += y_test.tolist()\n",
    "\n",
    "    return f1_score(y_tests, y_hats)\n",
    "\n",
    "X = pd.read_csv(\"features24h.csv\").drop(['pool_address', 'token_address'], axis=1)\n",
    "X, y = X.drop(\"label\", axis=1), X['label']\n",
    "\n",
    "ids, total_probs, total_targets = [], [], []\n",
    "skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "for fold, (t, v) in enumerate(skfolds.split(X, y)):\n",
    "    X_train, X_test = X.iloc[t], X.iloc[v]\n",
    "    y_train, y_test = y.iloc[t], y.iloc[v]\n",
    "\n",
    "    # func = lambda trial: objective(trial, X_train.copy(), y_train.copy())\n",
    "    # study = optuna.create_study(direction='maximize')\n",
    "    # study.optimize(func, n_trials=100)\n",
    "\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_scorings = model.predict_proba(X_test)[:, 1]\n",
    "    preds = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    sensibilitat = recall_score(y_test, preds)\n",
    "    precisio = precision_score(y_test, preds)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(\"{},{},{},{},{}\".format(accuracy, sensibilitat, precisio, f1, fold))\n",
    "    ids += X_test.index.tolist()\n",
    "    total_probs += preds.tolist()\n",
    "    total_targets += y_test.tolist()\n",
    "\n",
    "final_df = pd.DataFrame({'ids': ids, 'Pred': total_probs, 'Label': total_targets}).to_csv(\"scorings_24h_XGBoost.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
